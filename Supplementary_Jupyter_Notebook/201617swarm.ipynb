{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T16:23:05.409476Z",
     "start_time": "2019-02-15T16:23:05.382800Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "variable_folder = \"stored_variables/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T16:23:24.074926Z",
     "start_time": "2019-02-15T16:23:06.337780Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Import builtin\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime, date, time\n",
    "import copy\n",
    "import json\n",
    "\n",
    "#sci and num py\n",
    "import numpy as np\n",
    "import scipy.optimize as optimize\n",
    "from scipy.optimize import least_squares\n",
    "from scipy.interpolate import Rbf\n",
    "from scipy import interpolate\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "from numpy.linalg import norm\n",
    "from numpy.linalg import inv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#okada wrapper is crucial\n",
    "try: from okada_wrapper import dc3d0wrapper, dc3dwrapper \n",
    "except: print('Please install the Okada Wrapper module.\\\n",
    "            https://github.com/tbenthompson/okada_wrapper') \n",
    "\n",
    "# matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.spatial import ConvexHull\n",
    "import matplotlib.path as mpltPath\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "\n",
    "# Import plotly related stuff\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "from scipy.spatial import Delaunay\n",
    "import matplotlib.cm as cm\n",
    "from functools import reduce\n",
    "\n",
    "# For clustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.mixture\n",
    "import multiprocessing #!# may not need multiprocessing\n",
    "import sklearn\n",
    "\n",
    "# pyproj handles UTM projection\n",
    "import pyproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T16:23:24.594835Z",
     "start_time": "2019-02-15T16:23:24.081445Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get clustering info\n",
    "%run ./clustering_base_file.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T16:23:24.756857Z",
     "start_time": "2019-02-15T16:23:24.599170Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Functions for loading data. \n",
    "%run ./Load_Data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T16:23:25.150938Z",
     "start_time": "2019-02-15T16:23:24.762248Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get functions that are used for many mathematical calculations. Open that file for details. \n",
    "%run ./Calculation_Functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T16:23:25.387870Z",
     "start_time": "2019-02-15T16:23:25.161653Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Functions for fault splitting \n",
    "%run ./Fault_Splitting.ipynb #!# remove this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T16:23:25.634051Z",
     "start_time": "2019-02-15T16:23:25.394236Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get some fundamental functions for making figures. Open that file for details. \n",
    "%run ./Figure_Making_Functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T16:23:26.262803Z",
     "start_time": "2019-02-15T16:23:25.639990Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get some stress related stuff\n",
    "%run ./stress_base_file.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load Hypocenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T16:23:28.100069Z",
     "start_time": "2019-02-15T16:23:26.268878Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'focmec-gmt-utm-medi.reloc.dat' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c3dde63f6bec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load sequence data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mallHypo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhypoData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselectSequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'201617'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mallHypo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeogToMet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-c02651bed5a9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, minMag, selectSequence)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminMag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminMag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselectSequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselectSequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetHypocenters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetFocalAvailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-c02651bed5a9>\u001b[0m in \u001b[0;36mgetHypocenters\u001b[0;34m(self, selectSequence)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselectSequence\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'201617'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretINGV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadSecondSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminMag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminMag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-93bc72c1cd73>\u001b[0m in \u001b[0;36mloadSecondSequence\u001b[0;34m(minMag, onlyFocal, file)\u001b[0m\n\u001b[1;32m      1\u001b[0m def loadSecondSequence(minMag = None, onlyFocal = False,\n\u001b[1;32m      2\u001b[0m                        file = 'focmec-gmt-utm-medi.reloc.dat'):\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipinitialspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mlatFault\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLATITUDE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlonFault\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLONGITUDE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'focmec-gmt-utm-medi.reloc.dat' does not exist"
     ]
    }
   ],
   "source": [
    "# load sequence data \n",
    "\n",
    "allHypo = hypoData(selectSequence = '201617')\n",
    "allHypo.geogToMet()\n",
    "\n",
    "allHypo.labels=np.zeros(allHypo.mL.size)\n",
    "\n",
    "if False:\n",
    "    allHypo.plot3dclusters(pointSize=1, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## How do they distribute through time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T17:18:51.074669Z",
     "start_time": "2019-02-15T17:18:51.063744Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "times = allHypo.time.astype('float')\n",
    "labs = np.zeros(times.shape)\n",
    "windows = 10\n",
    "twinds = np.linspace(np.amin(times), np.amax(times), windows)\n",
    "for i, t in enumerate(twinds[:-1]):\n",
    "    labs[times>t] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T17:18:51.928670Z",
     "start_time": "2019-02-15T17:18:51.501345Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.axis('off')\n",
    "plotlabels = [twinds[i] for i in np.arange(windows)]\n",
    "xsLeg = np.zeros(twinds.size); ysLeg = twinds\n",
    "plt.scatter(xsLeg, ysLeg, c = twinds, cmap=cm.jet)\n",
    "for i, txt in enumerate(plotlabels):\n",
    "    plt.annotate(s = txt, xy = (xsLeg[i], ysLeg[i]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T17:18:53.770835Z",
     "start_time": "2019-02-15T17:18:53.755556Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ind = None\n",
    "keeper = labs != ind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T17:18:59.791464Z",
     "start_time": "2019-02-15T17:18:56.857917Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    # allHypo.plot3dclustersLeg = plot3dclustersLeg\n",
    "    allHypo.plot3dclusters(\n",
    "            x = allHypo.x[keeper], y = allHypo.y[keeper], z = allHypo.z[keeper],\n",
    "            labels = labs[keeper],\n",
    "            pointSize=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T16:24:13.056683Z",
     "start_time": "2019-02-15T16:24:13.052205Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot temporal change in time / direction of fault dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T03:39:17.967206Z",
     "start_time": "2019-02-13T03:39:15.314030Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Spectral clustering\n",
    "sp = spClust(minMag = 3, selectSequence='201617')\n",
    "sp.assign_labels=\"discretize\"\n",
    "sp.n_init=10\n",
    "sp.beta=1\n",
    "sp.n_clusters=10 # choose this before hand based on the 3 main faults\n",
    "\n",
    "sp.cluster()\n",
    "# spectral clustering is completed \n",
    "# sp.labels indicates cluster identities\n",
    "if False:\n",
    "    sp.plot3dclusters(pointSize=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T03:39:27.092734Z",
     "start_time": "2019-02-13T03:39:27.077285Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    sp.plot3dclusters(pointSize=2, save = False, lineWidthR=1e-10, \n",
    "        x = sp.x, y = sp.y, z = sp.z, labels = sp.labels\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## DBSCAN Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T17:35:59.522694Z",
     "start_time": "2019-02-14T17:35:55.786907Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# DBSCAN clustering\n",
    "db = dbClust(selectSequence='201617')\n",
    "db.eps=1 * 1e3\n",
    "db.min_samples=60\n",
    "db.fitdbscan() # cluster in modified axis system\n",
    "\n",
    "# plt.hist(db.labels)\n",
    "plt.show()\n",
    "# print(np.sum(db.labels==-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T17:36:20.577152Z",
     "start_time": "2019-02-14T17:36:20.570854Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# all points including noise\n",
    "if False:\n",
    "    db.plot3dclusters(pointSize=.7, save = False, name = 'dbscannewdata', lineWidthR=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T17:56:10.556047Z",
     "start_time": "2019-02-12T17:56:10.457151Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def plot3dclusters(self, pointSize=4, lineWidthR = 1/10, save = False, name = 'to_delete', \n",
    "#                       x=None, y=None, z=None, labels=None):\n",
    "#         if x is None:\n",
    "#             x = self.x\n",
    "#             y = self.y\n",
    "#             z = self.z\n",
    "#             labels = self.labels\n",
    "        \n",
    "#         scatterPlot = [go.Scatter3d(\n",
    "#             x=x,\n",
    "#             y=y,\n",
    "#             z=z,\n",
    "#             mode='markers',\n",
    "#             marker=dict(\n",
    "#                 size=pointSize,\n",
    "#                 color=labels,\n",
    "#                 colorscale='Jet',\n",
    "#                 line=dict(\n",
    "#                         color='rgb(0,0,0)',\n",
    "#                         width=lineWidthR \n",
    "#                     ),\n",
    "#                 opacity=1) )]\n",
    "        \n",
    "#         ############################ \n",
    "#         textFontDict = {'color':'red', 'size':18}\n",
    "#         ### north arrow\n",
    "# #         xNA = 6.5e3; yNA = 10e3; zNA = -14e3\n",
    "#         xR = 10e3\n",
    "#         xNA = np.amax(xR-3e3)\n",
    "#         yNA = 28e3#np.amax(self.y)\n",
    "#         zNA = -14e3#np.amin(self.z)\n",
    "#         yBase = yNA - 5e3\n",
    "#         northLine = go.Scatter3d(\n",
    "#             x=[xNA, xNA], y=[yBase, yNA], z=[zNA, zNA],\n",
    "#             text = np.array(['', 'N']),\n",
    "#             mode='lines+text',#Change?\n",
    "#             line  =dict(width = 5, color = '#7f7f7f'),\n",
    "#             textposition = 'middle left',\n",
    "#             textfont = textFontDict\n",
    "#         )\n",
    "\n",
    "#         northCone = dict(\n",
    "#             type = 'cone',\n",
    "#             colorscale = 'Greys',\n",
    "#             showscale = False,\n",
    "#             x = [xNA], y = [yNA], z = [zNA],\n",
    "#             u = [0], v = [2e3], w = [0]\n",
    "#             )\n",
    "        \n",
    "#         upLine = go.Scatter3d(\n",
    "#             x=[xNA, xNA], y=[yBase, yBase], z=[zNA, zNA+5e3],\n",
    "#             text = np.array(['', 'UP']),\n",
    "#             mode='lines+text',#Change?\n",
    "#             line  =dict(width = 5, color = '#7f7f7f'),\n",
    "#             textposition = 'middle left',\n",
    "#             textfont = textFontDict\n",
    "#         )\n",
    "        \n",
    "#         upCone = dict(\n",
    "#             type = 'cone',\n",
    "#             colorscale = 'Greys',\n",
    "#             showscale = False,\n",
    "#             x = [xNA], y = [yBase], z = [zNA+5e3],\n",
    "#             u = [0], v = [0], w = [2e3]\n",
    "#             )\n",
    "#         ###\n",
    "        \n",
    "#         ###  scale bar      \n",
    "#         xN = np.array([xR, xR, xR])\n",
    "#         yN = np.array([-10e3, -5e3, 0])+yNA\n",
    "#         zN = np.array([zNA, zNA, zNA])\n",
    "#         scaleBar = go.Scatter3d(\n",
    "#             x=xN,\n",
    "#             y=yN,\n",
    "#             z=zN,\n",
    "#             text = np.array(['', '10 km', '']),\n",
    "#             mode='lines+text',\n",
    "#             line  =dict(width = 15, color = '#7f7f7f'),\n",
    "#             textposition='middle right',\n",
    "#             textfont = textFontDict\n",
    "#         )\n",
    "#         ###\n",
    "#         scatterPlot.append(scaleBar)\n",
    "#         scatterPlot.append(northLine)\n",
    "#         scatterPlot.append(northCone)\n",
    "#         scatterPlot.append(upLine)\n",
    "#         scatterPlot.append(upCone)\n",
    "#         #########################\n",
    "        \n",
    "#         layout = go.Layout(\n",
    "#             showlegend=False,\n",
    "#             autosize=False,\n",
    "#             width=1000,\n",
    "#             height=1000,\n",
    "#             scene=dict(\n",
    "#                 camera=dict(eye=dict(x=1.75, y=-0.7, z= 0.75) ),\n",
    "#                 aspectmode = 'data',\n",
    "#                 xaxis = dict(showticklabels=False, title=''),\n",
    "#                 yaxis = dict(showticklabels=False, title=''),\n",
    "#                 zaxis = dict(showticklabels=False, title='')\n",
    "#                       )  \n",
    "#             )\n",
    "\n",
    "#         fig2 = go.Figure(data=scatterPlot, layout=layout)\n",
    "        \n",
    "#         if not save:\n",
    "#             iplot(fig2)\n",
    "#         elif save:\n",
    "#             py.iplot(fig2, filename = name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T17:36:44.421657Z",
     "start_time": "2019-02-14T17:36:44.412289Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inc = db.labels!= -1\n",
    "# inc = np.ones(inc.shape, dtype = 'bool')\n",
    "if False:\n",
    "    db.plot3dclusters(pointSize=1.2, save = False, lineWidthR=1e-10, \n",
    "        x = db.x[inc], y = db.y[inc], z = db.z[inc], labels = db.labels[inc]\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T03:41:03.529815Z",
     "start_time": "2019-02-13T03:41:03.515108Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    db.plot3dclusters(pointSize=1.2, save = False, lineWidthR=1e-10, \n",
    "        x = db.x[inc], y = db.y[inc], z = db.z[inc], labels = allHypo.time[inc].astype('float')\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T23:17:06.369060Z",
     "start_time": "2019-02-13T23:17:04.753082Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Agglomerative clustering\n",
    "\n",
    "class agClust(hypoData):\n",
    "    def __init__(self, minMag=None, selectSequence = None):\n",
    "        super().__init__(minMag=minMag, selectSequence = selectSequence)\n",
    "        \n",
    "        self.n_clusters=2\n",
    "        self.affinity='euclidean'\n",
    "        self.memory=None\n",
    "        self.connectivity=None\n",
    "        self.compute_full_tree='auto'\n",
    "        self.linkage='ward'\n",
    "        \n",
    "        \n",
    "    def fitAgClust(self):        \n",
    "        self.pTrans = sklearn.preprocessing.StandardScaler().fit_transform(self.p)\n",
    "        \n",
    "        self.output = sklearn.cluster.AgglomerativeClustering(\n",
    "            self.n_clusters,\n",
    "            affinity=self.affinity,\n",
    "            memory=self.memory,\n",
    "            connectivity=self.connectivity,\n",
    "            compute_full_tree=self.compute_full_tree,\n",
    "            linkage=self.linkage\n",
    "            ).fit(self.p)\n",
    "        \n",
    "        self.labels=self.output.labels_\n",
    " \n",
    "minMag = 3\n",
    "ag = agClust(minMag = minMag, selectSequence = '201617')\n",
    "ag.n_clusters = 15\n",
    "ag.fitAgClust()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T23:17:06.736826Z",
     "start_time": "2019-02-13T23:17:06.373878Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    ag.plot3dclusters(pointSize=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Makeing surfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here, I am trying to construct 3D surfaces to fit clusters. It isn't ready yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T03:42:23.016817Z",
     "start_time": "2019-02-13T03:42:22.998985Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# class manySurfaces3D:\n",
    "#     def __init__(self, terp, allHypo, splineNodesLine = 7):\n",
    "#         self.setTerp(terp)\n",
    "#         self.allHypo = allHypo\n",
    "#         self.splineNodesLine = splineNodesLine # temporary\n",
    "        \n",
    "#     def setTerp(self, terp):\n",
    "#         self.terp = terp\n",
    "        \n",
    "#         if terp.minMag is None:\n",
    "#             terp.minMag = -1e9 #arbitrarily low\n",
    "#         self.keepMag = allHypo.mL>=terp.minMag\n",
    "#         self.keepGen = self.keepMag\n",
    "        \n",
    "#     def interpolation(self, labelBounds = (0, None)):\n",
    "#         self.labelBounds = labelBounds\n",
    "#         self.allLabels = np.unique(self.terp.labels)\n",
    "#         self.labelsUse = self.allLabels[ \n",
    "#             (self.allLabels>=self.labelBounds[0]) * \n",
    "#             (self.allLabels< self.labelBounds[1]) ]\n",
    "#         self.surfObjs = []\n",
    "        \n",
    "#         for lab in self.labelsUse:\n",
    "#             booFault = self.terp.labels==lab\n",
    "\n",
    "#             xi = self.allHypo.x[self.keepGen][booFault]\n",
    "#             yi = self.allHypo.y[self.keepGen][booFault]\n",
    "#             zi = self.allHypo.z[self.keepGen][booFault] \n",
    "\n",
    "#             surfacei = interp(xi, yi, zi,\n",
    "#                            eps=.01, minPlaneDist = 10000,exp=2,\n",
    "#                            splineNodesStrike = splineNodesLine, # Change\n",
    "#                               splineNodesDip = splineNodesLine) # Change\n",
    "            \n",
    "#             self.surfObjs.append(surfacei)\n",
    "                \n",
    "#     def makeSurfaces(self, gridNodesStrike = 40, gridNodesDip = 24):     \n",
    "#         for lab in self.labelsUse:\n",
    "#             self.surfObjs[lab].gridNodesStrike = gridNodesStrike\n",
    "#             self.surfObjs[lab].gridNodesDip = gridNodesDip\n",
    "\n",
    "#             #the outermost cell center be inset from the outermost part of surface:\n",
    "#             shiftS = (np.amax(self.surfObjs[lab].pS) - np.amin(self.surfObjs[lab].pS)\n",
    "#                      ) / self.surfObjs[lab].gridNodesStrike * .5\n",
    "#             shiftD = (np.amax(self.surfObjs[lab].pD) - np.amin(self.surfObjs[lab].pD)\n",
    "#                      ) / self.surfObjs[lab].gridNodesDip * .5\n",
    "            \n",
    "#             # Generate points on surface\n",
    "#             self.surfObjs[lab].splineInterp(\n",
    "#                 cutPoints=True, sEdgeShift = shiftS, dEdgeShift = shiftD)\n",
    "            \n",
    "            \n",
    "#     def plotManySurfaces3D(self, pointSize = 2):\n",
    "#         data = []\n",
    "#         for lab in self.labelsUse:\n",
    "#             shape = (self.surfObjs[lab].gridNodesStrike, \n",
    "#                      self.surfObjs[lab].gridNodesDip)\n",
    "            \n",
    "#             iS = self.surfObjs[lab].interpS\n",
    "#             iD = self.surfObjs[lab].interpD\n",
    "#             xs = self.surfObjs[lab].interpX\n",
    "#             ys = self.surfObjs[lab].interpY \n",
    "#             zs = self.surfObjs[lab].interpZ\n",
    "#             x = self.surfObjs[lab].x\n",
    "#             y = self.surfObjs[lab].y\n",
    "#             z = self.surfObjs[lab].z\n",
    "            \n",
    "#             points2D=np.vstack([iS,iD]).T\n",
    "#             tri=Delaunay(points2D)\n",
    "\n",
    "#             surfacePlot=plotly_trisurf(xs, ys, zs,\n",
    "#                                        tri.simplices, colormap=cm.cubehelix, plot_edges=None)\n",
    "\n",
    "\n",
    "#             scatterPlot = go.Scatter3d(x=x, y=y, z=z,\n",
    "#                             mode='markers',\n",
    "#                             marker=dict(\n",
    "#                                 size=pointSize,\n",
    "#         #                         color=labels,\n",
    "#                                 colorscale='Jet',\n",
    "#                                 line=dict(\n",
    "#                                         color='rgb(0,0,0)',\n",
    "#                                         width=1 \n",
    "#                                     ),\n",
    "#                                 opacity=1) ) \n",
    "#             surfacePlot.append(scatterPlot)\n",
    "\n",
    "#             data = data + surfacePlot\n",
    "\n",
    "#         layout = go.Layout( scene=dict( aspectmode = 'data' ) )\n",
    "\n",
    "#         fig = go.Figure(data=data, layout=layout) \n",
    "#         iplot(fig)\n",
    "\n",
    "# #     plotManySurfaces3D(surfObjs, allLabels)\n",
    "\n",
    "        \n",
    "# instance = manySurfaces3D(db, allHypo)   \n",
    "# instance.interpolation(labelBounds = (0, 5) )\n",
    "# instance.makeSurfaces()\n",
    "# instance.plotManySurfaces3D()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increase dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## How to quantify similarity in orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T16:24:29.620566Z",
     "start_time": "2019-02-15T16:24:29.601187Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def vectSimilarity(v1, v2 = None, under90 = False,\n",
    "            dotMethod = True):\n",
    "    # similarity is from 0 to 1 if v1 and v2 are unit vectors\n",
    "    if v2 is None:\n",
    "        v2 = v1\n",
    "            \n",
    "    sim = np.matmul(v1, v2.T) # dot products\n",
    "            \n",
    "    if under90:\n",
    "        sim = np.abs(sim)\n",
    "            \n",
    "    if dotMethod:\n",
    "        return sim\n",
    "    \n",
    "    else:\n",
    "        sim[sim>1] = 1\n",
    "        sim[sim<-1] = -1\n",
    "        angles = np.arccos(sim)\n",
    "        del sim\n",
    "        return angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I can use the angle between focal mechanism planes. but I can't simply add them as they always sum to the same number. Instead, I need to norm the reslults. The PROBLEM is that it turns out that well aligned focal mechanisms give a higher angle mismatch if I try to count all 4 combinations of possible focal correlations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T16:24:31.435903Z",
     "start_time": "2019-02-15T16:24:30.732198Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "points = 180\n",
    "print('angles go from 0 to 180')\n",
    "\n",
    "s1f = np.linspace(0, np.pi, points)\n",
    "d1f = np.zeros(points) + np.pi / 2\n",
    "r1f = np.zeros(points)\n",
    "sdr = [[s1f, d1f, r1f], [s1f+np.pi/2, d1f, r1f]]\n",
    "def orientSimAngle(sdr, normexp = 2):\n",
    "    orientSim = [[],[]]\n",
    "    under90=True\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ni, __ = faultUnitVectors(*sdr[i])\n",
    "            nj, __ = faultUnitVectors(*sdr[j])\n",
    "            simij = vectSimilarity(ni, nj, under90=under90, dotMethod = False)\n",
    "            orientSim[i].append(simij)\n",
    "\n",
    "    finOrientSim = np.zeros(orientSim[0][0].shape)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            finOrientSim+=orientSim[i][j] ** normexp\n",
    "\n",
    "    finOrientSim = finOrientSim ** (1/normexp)\n",
    "    finOrientSim -= np.amin(finOrientSim)\n",
    "    finOrientSim *= 1/np.amax(finOrientSim)\n",
    "    return finOrientSim\n",
    "finOrientSim = orientSimAngle(sdr)\n",
    "plt.imshow(finOrientSim, interpolation = 'bilinear', origin  = 'lower')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T21:25:23.548746Z",
     "start_time": "2019-02-13T21:25:23.538990Z"
    },
    "hidden": true
   },
   "source": [
    "It turns out that the dot product is lowest for well aligned focal mechanisms. Thus, this doesn't seem to work either. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T16:24:32.578305Z",
     "start_time": "2019-02-15T16:24:31.971218Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def dotToAffin(dot, beta):\n",
    "    dot[dot>1.] = 1\n",
    "    angles = np.arccos(dot) # assuming only unit vectors were used\n",
    "    ret = np.exp(-beta * angles / angles.std())\n",
    "    return ret\n",
    "\n",
    "def orientSimAffin(sdr, normexp = 1, beta = 1):\n",
    "    print('should beta be negative somewhere?')\n",
    "    orientSim = [[],[]]\n",
    "    under90=True\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ni, __ = faultUnitVectors(*sdr[i])\n",
    "            nj, __ = faultUnitVectors(*sdr[j])\n",
    "            simij = vectSimilarity(ni, nj, under90=under90, dotMethod=True)\n",
    "#             simij = dotToAffin(simij, beta = beta)\n",
    "            orientSim[i].append(simij)\n",
    "\n",
    "    finOrientSim = np.zeros(orientSim[0][0].shape)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            finOrientSim+=orientSim[i][j] ** normexp\n",
    "\n",
    "    finOrientSim = finOrientSim ** (1/normexp)\n",
    "    finOrientSim -= np.amin(finOrientSim)\n",
    "    finOrientSim *= 1/np.amax(finOrientSim)\n",
    "    return finOrientSim\n",
    "finOrientSim = orientSimAffin(sdr)\n",
    "plt.imshow(finOrientSim, interpolation = 'bilinear', origin  = 'lower')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Another option would be to take the dot product of normals and find only one possible orientation match rather than include both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Another option would be to find what is the minimum angle I could rotate one focal mechanism to get the second focal mechanism. The lower the angle, the better the fit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Possibly there is already a formulation to determine the similarity of two planes (that is orientation as well as position). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantify similarity in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T16:24:51.357926Z",
     "start_time": "2019-02-15T16:24:49.874893Z"
    }
   },
   "outputs": [],
   "source": [
    "selectSequence = '201617'\n",
    "allHypo = hypoData(selectSequence=selectSequence)  \n",
    "        \n",
    "FA = ~( (allHypo.st1 == 0) * (allHypo.st2 == 0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T16:24:59.095898Z",
     "start_time": "2019-02-15T16:24:59.035908Z"
    }
   },
   "outputs": [],
   "source": [
    "beta = 1\n",
    "t=allHypo.time[FA]\n",
    "timeDist = np.zeros((t.size, t.size))\n",
    "for i in np.arange(t.size):\n",
    "    timeDist[i] = np.abs(t[i] - t)\n",
    "timeDist -= timeDist.min()\n",
    "timeDist *= 1/timeDist.max()\n",
    "timeAffin = np.exp(-beta * timeDist / timeDist.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Similarity matrix in spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T16:25:56.741571Z",
     "start_time": "2019-02-15T16:25:53.433009Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# second swarm\n",
    "beta = 1\n",
    "n_clusters = 5\n",
    "n_init = 10\n",
    "assign_labels=\"discretize\"\n",
    "gamma=1\n",
    "\n",
    "selectSequence = '201617'\n",
    "allHypo = hypoData(selectSequence=selectSequence)  \n",
    "        \n",
    "FA = ~( (allHypo.st1 == 0) * (allHypo.st2 == 0) )\n",
    "s1 = allHypo.st1[FA]\n",
    "d1 = allHypo.dp1[FA]\n",
    "r1 = allHypo.rk1[FA]\n",
    "s2 = allHypo.st2[FA]\n",
    "d2 = allHypo.dp2[FA]\n",
    "r2 = allHypo.rk2[FA]\n",
    "sdr = [[s1, d1, r1], [s2, d2, r2]]\n",
    "\n",
    "finOrientSim = orientSimAffin(sdr)\n",
    "        \n",
    "dists = distances(\n",
    "          allHypo.x[allHypo.FA],\n",
    "          allHypo.y[allHypo.FA],\n",
    "          allHypo.z[allHypo.FA],\n",
    "          allHypo.x[allHypo.FA],\n",
    "          allHypo.y[allHypo.FA],\n",
    "          allHypo.z[allHypo.FA]\n",
    "         )\n",
    "distSim = np.exp(-beta * dists / dists.std())\n",
    "\n",
    "finSim = timeAffin*distSim*finOrientSim\n",
    "\n",
    "spBase = sklearn.cluster.SpectralClustering(\n",
    "\n",
    "        n_clusters=n_clusters,\n",
    "        n_init=n_init,\n",
    "        assign_labels=assign_labels,\n",
    "        random_state=np.random.RandomState(1),\n",
    "        gamma=1,\n",
    "        affinity='precomputed'\n",
    "\n",
    "        )\n",
    "\n",
    "result = spBase.fit(finSim)\n",
    "\n",
    "sp = spClust(minMag = 0, selectSequence=selectSequence)\n",
    "sp.results = result\n",
    "sp.labels = result.labels_\n",
    "\n",
    "if False:\n",
    "    sp.plot3dclusters(pointSize=3,\n",
    "                     x=allHypo.x[allHypo.FA],\n",
    "                     y=allHypo.y[allHypo.FA],\n",
    "                     z=allHypo.z[allHypo.FA],\n",
    "                     labels=sp.labels,\n",
    "                     \n",
    "                     save = False, name = 'newData')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Similarity matrix in DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T16:25:59.506160Z",
     "start_time": "2019-02-15T16:25:57.984654Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selectSequence = '201617'\n",
    "allHypo = hypoData(selectSequence=selectSequence)\n",
    "class dbClust(hypoData):\n",
    "    def __init__(self, minMag=None, selectSequence = None):\n",
    "        super().__init__(minMag=minMag, selectSequence = selectSequence)\n",
    "        self.sort=False\n",
    "        \n",
    "    def fitdbscan(self, weight=None):        \n",
    "#         self.pTrans = sklearn.preprocessing.StandardScaler().fit_transform(self.p)\n",
    "        self.pTrans=self.p\n",
    "        \n",
    "        if weight is None:       \n",
    "            self.db = sklearn.cluster.DBSCAN(\n",
    "                eps=self.eps, min_samples=self.min_samples, \n",
    "                n_jobs=multiprocessing.cpu_count()-1\n",
    "                ).fit(self.pTrans)\n",
    "        elif weight is not None:\n",
    "            self.db = sklearn.cluster.DBSCAN(\n",
    "                eps=self.eps, min_samples=self.min_samples, \n",
    "                n_jobs=multiprocessing.cpu_count()-1\n",
    "                ).fit(self.pTrans, weight)   \n",
    "        \n",
    "        self.labels=self.db.labels_\n",
    "        \n",
    "    def setLabels(self, labels):\n",
    "        self.labels = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T16:25:59.806020Z",
     "start_time": "2019-02-15T16:25:59.510884Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sdr = [[s1, d1, r1], [s2, d2, r2]]\n",
    "orientSim = [[],[]]\n",
    "under90=True\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ni, __ = faultUnitVectors(*sdr[i])\n",
    "        nj, __ = faultUnitVectors(*sdr[j])\n",
    "        simij = vectSimilarity(ni, nj, under90=under90)\n",
    "        orientSim[i].append(simij)\n",
    "        \n",
    "dists = distances(\n",
    "          allHypo.x[allHypo.FA],\n",
    "          allHypo.y[allHypo.FA],\n",
    "          allHypo.z[allHypo.FA],\n",
    "          allHypo.x[allHypo.FA],\n",
    "          allHypo.y[allHypo.FA],\n",
    "          allHypo.z[allHypo.FA]\n",
    "         )\n",
    "\n",
    "def stretchDimensions(p):\n",
    "    \"\"\"p shape should be (points, dimensions)\"\"\"\n",
    "    pN = np.zeros(p.shape)\n",
    "    for i in np.arange(p.shape[1]):\n",
    "        pN[:,i]  = p[:,i]/(np.amax(p[:,i])-np.amin(p[:,i]) )\n",
    "        pN[:,i] -= np.amin(pN[:,i])\n",
    "        \n",
    "    return pN\n",
    "\n",
    "p = np.array([\n",
    "    allHypo.x[allHypo.FA],\n",
    "    allHypo.y[allHypo.FA],\n",
    "    allHypo.z[allHypo.FA]\n",
    "    ]).T\n",
    "\n",
    "pN = stretchDimensions(p)\n",
    "\n",
    "distsN = distances(pN[:,0],\n",
    "                  pN[:,1],\n",
    "                  pN[:,2],\n",
    "                  pN[:,0],\n",
    "                  pN[:,1],\n",
    "                  pN[:,2])\n",
    "\n",
    "# finOrientSim = np.zeros(orientSim[0][0].shape)\n",
    "# for i in range(2):\n",
    "#     for j in range(2):\n",
    "#         print('changing orientSim')\n",
    "#         finOrientSim+=orientSim[i][j] ** 2\n",
    "# finOrientSim = np.sqrt(finOrientSim)\n",
    "        \n",
    "# # finOrientSim *= 1/4\n",
    "\n",
    "# orientDist = 1-finOrientSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T16:26:00.504493Z",
     "start_time": "2019-02-15T16:25:59.956600Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "finOrientSim = np.zeros(orientSim[0][0].shape)\n",
    "normexp = 2\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        print('changing orientSim')\n",
    "        finOrientSim+=orientSim[i][j] ** normexp\n",
    "finOrientSim = finOrientSim ** (1/normexp)\n",
    "plt.hist(finOrientSim[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T16:26:07.582446Z",
     "start_time": "2019-02-15T16:26:05.697752Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# not implimented yet, this is the next task\n",
    "# DBSCAN clustering\n",
    "dbdim = dbClust(selectSequence='201617')\n",
    "# dbdim.fitdbscan() # cluster in modified axis system\n",
    "# plt.hist(dbdim.labels)\n",
    "eps = .1#* 1e3\n",
    "min_samples = 15\n",
    "\n",
    "dbR = sklearn.cluster.DBSCAN(eps = eps, min_samples=min_samples, metric = 'precomputed')\n",
    "\n",
    "pFinal = distsN\n",
    "dbext = dbR.fit(pFinal)\n",
    "dbext.labels_\n",
    "# plt.hist(dbext.labels_)\n",
    "# plt.show()\n",
    "\n",
    "dbdim.labels = dbext.labels_\n",
    "\n",
    "print(dbdim.labels)\n",
    "\n",
    "if True:\n",
    "    dbdim.plot3dclusters(x=dbdim.x[dbdim.FA],\n",
    "                         y=dbdim.y[dbdim.FA],\n",
    "                         z=dbdim.z[dbdim.FA],\n",
    "                         labels=dbdim.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## include orientation in dbscan, not using similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T16:27:20.047947Z",
     "start_time": "2019-02-15T16:27:18.549299Z"
    }
   },
   "outputs": [],
   "source": [
    "# DBSCAN clustering\n",
    "dbdim = dbClust(selectSequence='201617')\n",
    "dbdim.eps=1 \n",
    "dbdim.min_samples=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T16:27:21.669875Z",
     "start_time": "2019-02-15T16:27:21.661236Z"
    }
   },
   "outputs": [],
   "source": [
    "eps = .25 #* 1e3\n",
    "min_samples = 5\n",
    "\n",
    "dbR = sklearn.cluster.DBSCAN(eps = eps, min_samples=min_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T16:27:50.891281Z",
     "start_time": "2019-02-15T16:27:50.864805Z"
    }
   },
   "outputs": [],
   "source": [
    "p = np.array([\n",
    "#               dbdim.x, \n",
    "#               dbdim.y, \n",
    "#               dbdim.z, \n",
    "              dbdim.st1, \n",
    "              dbdim.dp1,\n",
    "              dbdim.st2, \n",
    "              dbdim.dp2\n",
    "#               dbdim.time.astype('float')\n",
    "             ]).T\n",
    "\n",
    "p = p[dbdim.FA, :]\n",
    "for i in np.arange(p.shape[1]):\n",
    "    view = p[:,i]\n",
    "    view -= view.mean()\n",
    "    view *= 1 / np.amax(np.abs(view))\n",
    "    \n",
    "pStretch = np.array([1, 1, 1, \n",
    "                     1, 1, 1, 1, 1])\n",
    "for i in np.arange(p.shape[1]):\n",
    "    p[i] *= pStretch[i]\n",
    "pTrans = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T16:27:58.962758Z",
     "start_time": "2019-02-15T16:27:58.522373Z"
    }
   },
   "outputs": [],
   "source": [
    "# pTrans = sklearn.preprocessing.StandardScaler().fit_transform(p)\n",
    "dbext = dbR.fit(pTrans)\n",
    "dbdim.labels = dbext.labels_\n",
    "plt.hist(dbdim.labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T16:28:04.218610Z",
     "start_time": "2019-02-15T16:28:00.670601Z"
    }
   },
   "outputs": [],
   "source": [
    "dbdim.labels = np.zeros(FA.size)-1\n",
    "dbdim.labels[FA] = dbext.labels_\n",
    "dbdim.plot3dclusters(pointSize=np.ones(FA.size)*1.5+FA*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T16:28:05.055206Z",
     "start_time": "2019-02-15T16:28:04.237932Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    dbdim.plot3dclusters(x=dbdim.x[dbdim.FA],\n",
    "                         y=dbdim.y[dbdim.FA],\n",
    "                         z=dbdim.z[dbdim.FA],\n",
    "                         labels=dbdim.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to be the problem that s1 of one quake might correspond to s2 of another, yet they will always be compared such that s1 is against s1, not s2. The problem extends to other orientations obviously. Thus, a similarity matrix is probably better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T17:06:40.200770Z",
     "start_time": "2019-02-15T17:06:40.190722Z"
    }
   },
   "outputs": [],
   "source": [
    "s = 130 * np.pi / 180\n",
    "\n",
    "vx = np.sin(s)\n",
    "vy = np.cos(s)\n",
    "\n",
    "Q = np.array([vx, vy, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T17:10:58.361749Z",
     "start_time": "2019-02-15T17:10:58.329639Z"
    }
   },
   "outputs": [],
   "source": [
    "rotateUniVec??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-15T17:08:07.531976Z",
     "start_time": "2019-02-15T17:08:01.582496Z"
    }
   },
   "outputs": [],
   "source": [
    "x = allHypo.x\n",
    "y = allHypo.y\n",
    "z = allHypo.z\n",
    "p = np.array([x, y, z]).T\n",
    "\n",
    "xPrime = \n",
    "\n",
    "# xPrime = np.zeros(x.shape)\n",
    "# yPrime = np.zeros(y.shape)\n",
    "# zPrime = np.zeros(z.shape)\n",
    "\n",
    "# xPrime\n",
    "\n",
    "# for i in np.arange(x.size):\n",
    "#     xPrime[i], yPrime[i], zPrime[i] = np.dot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
