{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T18:33:09.370774Z",
     "start_time": "2019-03-10T18:33:02.940360Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pyproj\n",
    "import re\n",
    "from datetime import date, time, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T18:33:10.314315Z",
     "start_time": "2019-03-10T18:33:09.394165Z"
    }
   },
   "outputs": [],
   "source": [
    "%run ../Load_Data.ipynb\n",
    "%run ../Calculation_Functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T19:48:44.935006Z",
     "start_time": "2019-03-10T19:48:44.881469Z"
    }
   },
   "outputs": [],
   "source": [
    "# This both loads the data from the INGV file,\n",
    "# and it calculates slip from the provided radius and mL\n",
    "\n",
    "def loadINGVTest(minMagnitude=0, onlyFocal = False): \n",
    "    \"\"\"Returns: (latitude, longitude, depth,\n",
    "    mL, radius, ST1, DIP1, RK1, ST2, DIP2, RK2, time, SLIP)\n",
    "    \n",
    "    Provide maxMagnitude to load only earthquake with higher than that magnitude\n",
    "    Only focal is boolean to indicate if earthquake with no focal mechanisms are desired\n",
    "    \n",
    "    Angles are returned in radians\n",
    "    slip and depth are in meters\n",
    "    \"\"\"\n",
    "\n",
    "    # We've had some problems with the address of the file. This should fix it.\n",
    "    try:\n",
    "        file=open('LAquila_2009_ALLinONE_unpub.out')\n",
    "    except:\n",
    "        url = '/work/Course'#= os.getcwd()\n",
    "        file=open(url+'/LAquila_2009_ALLinONE_unpub.out')\n",
    "        \n",
    "    maxLines = sum(1 for lines in file)\n",
    "    file.seek(0)\n",
    "    splitlines = []\n",
    "    for i in range(maxLines):\n",
    "        if i == 0:\n",
    "            next(file)\n",
    "        else:\n",
    "            splitlines.append(file.readline().split())\n",
    "            \n",
    "    dataSize=len(splitlines)\n",
    "    year=np.zeros(dataSize,np.int)\n",
    "    month=np.zeros(dataSize,np.int)    \n",
    "    day=np.zeros(dataSize,np.int)  \n",
    "    hours=np.zeros(dataSize,np.int)      \n",
    "    minutes=np.zeros(dataSize,np.int)    \n",
    "    seconds=np.zeros(dataSize,np.int)    \n",
    "    latitude=np.zeros(dataSize,np.float)    \n",
    "    longitude=np.zeros(dataSize,np.float)  \n",
    "    depth=np.zeros(dataSize,np.float)      \n",
    "    ML=np.zeros(dataSize,np.float)    \n",
    "    err=np.zeros(dataSize,np.float)    \n",
    "    radius=np.zeros(dataSize,np.float)    \n",
    "    ID=np.zeros(dataSize,np.int)    \n",
    "    ST1=np.zeros(dataSize,np.float)   \n",
    "    DIP1=np.zeros(dataSize,np.float)   \n",
    "    RK1=np.zeros(dataSize,np.float)   \n",
    "    ST2=np.zeros(dataSize,np.float)     \n",
    "    DIP2=np.zeros(dataSize,np.float) \n",
    "    RK2=np.zeros(dataSize,np.float)  \n",
    "    DS=np.zeros(dataSize,np.float)\n",
    "    tt=np.zeros(dataSize,dtype='datetime64[s]')\n",
    "    ind = np.zeros(dataSize,np.int)\n",
    "    fty = np.empty(dataSize, object)\n",
    "    \n",
    "    for data in np.arange(dataSize):\n",
    "        latitude[data]=float(splitlines[data][6])\n",
    "        longitude[data]=float(splitlines[data][7])    \n",
    "        depth[data]=float(splitlines[data][8]) * 1000 # meters\n",
    "        ML[data]=float(splitlines[data][9])\n",
    "        radius[data]=float(splitlines[data][11]) # meters\n",
    "        try:\n",
    "            ind[data]=int(splitlines[data][12])\n",
    "        except:\n",
    "            indWithLetter = splitlines[data][12]\n",
    "            ind[data]=int(re.sub(\"\\D\", \"\", indWithLetter) )         \n",
    "        ST1[data]=float(splitlines[data][13]) * np.pi / 180 \n",
    "        DIP1[data]=float(splitlines[data][14]) * np.pi / 180 \n",
    "        RK1[data]=float(splitlines[data][15]) * np.pi / 180 \n",
    "        ST2[data]=float(splitlines[data][16]) * np.pi / 180 \n",
    "        DIP2[data]=float(splitlines[data][17]) * np.pi / 180 \n",
    "        RK2[data]=float(splitlines[data][18])  * np.pi / 180 \n",
    "        year[data]=float(splitlines[data][0])\n",
    "        month[data]=float(splitlines[data][1])\n",
    "        day[data]=float(splitlines[data][2])\n",
    "        hours[data]=float(splitlines[data][3])\n",
    "        minutes[data]=float(splitlines[data][4])\n",
    "        seconds[data]=float(splitlines[data][5])\n",
    "        d = date(year[data], month[data], day[data])\n",
    "        t = time(hours[data], minutes[data])\n",
    "        dt = datetime.combine(d, t)\n",
    "        tt[data] = dt\n",
    "        \n",
    "        if len(splitlines[data])>19:\n",
    "            fty[data] = splitlines[data][19]\n",
    "        else:\n",
    "            fty[data] = '0'    \n",
    "\n",
    "    #Here we calculate displacement based on magnitude and radius. \n",
    "    #I think we calculated to go from a circular fault to a rectangular fault?\n",
    "    Mo=10**(1.5*ML+16.1)/1e7\n",
    "    SLIP = Mo/(2/3*3e10*radius**2*3.14) #slip is displacement in m\n",
    "    #\n",
    "    \n",
    "    #boolean array that selects only the quakes with a rupture mechanism\n",
    "    if onlyFocal:\n",
    "        selectQuakesST1 = ~( (ST1 == 0) * (ST2==0) * (DIP1==0) * (DIP2==0) * (RK1==0) * (RK2==0) )\n",
    "    else:\n",
    "        selectQuakesST1 = True\n",
    "        \n",
    "    selectQuakesML = ML>minMagnitude#max magnitude is the highest magnitude we want to load\n",
    "    selectQuakes = selectQuakesST1 * selectQuakesML # selectQuakes is boolean for events we want to load\n",
    "        \n",
    "    return[ latitude[selectQuakes].copy(), longitude[selectQuakes].copy(), depth[selectQuakes].copy(),\n",
    "            ML[selectQuakes].copy(), radius[selectQuakes].copy(), ST1[selectQuakes].copy(),\n",
    "            DIP1[selectQuakes].copy(), RK1[selectQuakes].copy(), ST2[selectQuakes].copy(), DIP2[selectQuakes].copy(),\n",
    "            RK2[selectQuakes].copy(), tt[selectQuakes].copy(), SLIP[selectQuakes].copy(), \n",
    "            fty[selectQuakes.copy()], ind[selectQuakes.copy()] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T19:49:05.547928Z",
     "start_time": "2019-03-10T19:49:05.534358Z"
    }
   },
   "outputs": [],
   "source": [
    "def compInds(ind1, ind2, returnExtra = False):\n",
    "    mapArr = np.zeros(ind1.shape, dtype = np.int32)\n",
    "    duplicated = []\n",
    "    missing = []\n",
    "\n",
    "    for i in range(ind1.size):\n",
    "        indMap = np.where(ind1[i]==ind2)[0]\n",
    "        if indMap.size == 0:\n",
    "            missing.append([i, ind1[i]])\n",
    "            mapArr[i] = 0\n",
    "        elif indMap.size == 1:\n",
    "            mapArr[i] = indMap[0]\n",
    "        elif indMap.size > 1:\n",
    "            mapArr[i] = indMap[0]\n",
    "            duplicated.append([i, indMap, ind1[i], np.array([ind2[indMap]])])\n",
    "    if not returnExtra:\n",
    "        return mapArr\n",
    "    else:\n",
    "        return mapArr, duplicated, missing\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T19:49:05.547928Z",
     "start_time": "2019-03-10T19:49:05.534358Z"
    }
   },
   "outputs": [],
   "source": [
    "def compInds(ind1, ind2, returnExtra = False):\n",
    "    mapArr = np.zeros(ind1.shape, dtype = np.int32)\n",
    "    duplicated = []\n",
    "    missing = []\n",
    "\n",
    "    for i in range(ind1.size):\n",
    "        indMap = np.where(ind1[i]==ind2)[0]\n",
    "        if indMap.size == 0:\n",
    "            missing.append([i, ind1[i]])\n",
    "            mapArr[i] = 0\n",
    "        elif indMap.size == 1:\n",
    "            mapArr[i] = indMap[0]\n",
    "        elif indMap.size > 1:\n",
    "            mapArr[i] = indMap[0]\n",
    "            duplicated.append([i, indMap, ind1[i], np.array([ind2[indMap]])])\n",
    "    if not returnExtra:\n",
    "        return mapArr\n",
    "    else:\n",
    "        return mapArr, duplicated, missing\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T19:49:05.547928Z",
     "start_time": "2019-03-10T19:49:05.534358Z"
    }
   },
   "outputs": [],
   "source": [
    "def compInds2(ind1, ind2):\n",
    "    mapArr12 = []\n",
    "    mapArr21 = []\n",
    "\n",
    "    for i in range(ind1.size):\n",
    "        indMap = np.where(ind1[i]==ind2)[0]\n",
    "        if indMap.size > 0:\n",
    "            mapArr12.append(i)   \n",
    "            mapArr21.append(indMap[0])\n",
    "\n",
    "    return np.array(mapArr12), np.array(mapArr21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mLtomW(mL):\n",
    "    # From MunafÃ² et al., 2016 - BSSA\n",
    "    toBig = mL>4\n",
    "    if toBig.sum() > 0:\n",
    "        print(toBig.sum(), ' # larger than mL 4. Calculation ran anyway.: mL = ', mL[toBig])\n",
    "    mW = mL*2/3 + 1.15\n",
    "        \n",
    "    return mW\n",
    "\n",
    "def mWtomO(mW):\n",
    "\n",
    "    # old implementation commented out\n",
    "    #     mO = 10 ** (1.5 * mW + 16.1)\n",
    "    #     mO = mO * 1e-5 * 1e-2 # 1d = 1e-5N   1m = 1e-2cm\n",
    "\n",
    "    mO = 10 ** (3/2 * (mW + 6.07) ) # Hanks and Kanamori (1979)\n",
    "    return mO\n",
    "\n",
    "def mOtomW(mO):\n",
    "    mW = 2/3 * np.log10(mO) - 6.07\n",
    "    return mW\n",
    "\n",
    "def mOtoRad(mO, stressDrop, P):\n",
    "    \"\"\"P is Poisson\"\"\"\n",
    "    # Cambiotti described this\n",
    "    rad = 1/2 * (\n",
    "            3/2 * \n",
    "           (2-P)/(1-P) * \n",
    "           (mO / stressDrop)\n",
    "        \n",
    "          ) ** (1/3) \n",
    "    return rad\n",
    "\n",
    "def radTomO(rad, stressDrop, P):\n",
    "    mO = (rad*2) ** 3 * 2/3 * (1-P)/(2-P) * stressDrop\n",
    "    return mO\n",
    "    \n",
    "\n",
    "def slipConstant(shearMod, area, moment):\n",
    "    # From moment = shearMod * area * slip\n",
    "    slipConstant = moment / (shearMod * area)\n",
    "    return slipConstant\n",
    "\n",
    "def ellipSlipMax(slipAv, area, yMax, xMax):\n",
    "    # I wrote the solution to this. It's found by suggesting that moment is conserved\n",
    "    # moving from an constant slip to elliptical slip. \n",
    "    sMax = 3/(2 * np.pi) * (slipAv * area) / (yMax * xMax)\n",
    "    return sMax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02-28-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T19:48:49.239131Z",
     "start_time": "2019-03-10T19:48:45.894025Z"
    }
   },
   "outputs": [],
   "source": [
    "[latold, lonold, dold, mold, rold, s1old, \n",
    "    d1old, rk1old, s2old, d2old, r2old, told, sold, ftyold, indold\n",
    "    ] = loadINGVTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latold.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T19:49:04.560526Z",
     "start_time": "2019-03-10T19:49:04.219928Z"
    }
   },
   "outputs": [],
   "source": [
    "fold     = 'LAquila_2009_ALLinONE_unpub.out'\n",
    "fnew     = 'LaqAll.final' # 'Brennan_Aquila2009_51k_FocMec_CMT.dat.final'\n",
    "\n",
    "dnew     = pd.read_csv(fnew, delimiter= '\\t', skipinitialspace=True)\n",
    "\n",
    "mnew     = dnew.mag.values\n",
    "indnew   = dnew.id_dd.values\n",
    "latnew   = dnew.lat.values\n",
    "lonnew   = dnew.lon.values\n",
    "depthnew = dnew.dep.values\n",
    "timenew  = dnew.OriginTime.values.astype('datetime64')\n",
    "ftynew   = dnew.fty.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapArrNOList, presentNOList = compInds2(indnew, indold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  # larger than mL 4. Calculation ran anyway.: mL =  [4.6]\n",
      "[0.52385544 0.29435625 0.23516824 ... 0.00097418 0.00090221 0.00090221]\n",
      "are my units correct?\n"
     ]
    }
   ],
   "source": [
    "stressDrop = 3e6\n",
    "P = .25\n",
    "shearMod = 26e9\n",
    "\n",
    "risbad = np.logical_or((ftynew == 'MP'), (ftynew == '0'))\n",
    "rCross = np.zeros(lonnew.shape)\n",
    "mW = np.zeros(lonnew.shape)\n",
    "rCross[mapArrNOList] = rold[presentNOList]\n",
    "rCross[risbad] = 0\n",
    "\n",
    "# have r where it is good. get moment from it. \n",
    "mO = radTomO(rCross, stressDrop, P)\n",
    "# mO = rCross ** 3 * 3e6 * 16 / 7\n",
    "mO[risbad]=0\n",
    "\n",
    "# have mO from r... now need mo for other events, get it from ml:\n",
    "mO[risbad] = mWtomO( mLtomW(mnew[risbad]) )\n",
    "\n",
    "# have all moments. Now go back to find rad for events where I didn't previously have it. \n",
    "rCross[risbad] = mOtoRad(mO[risbad], stressDrop, P)\n",
    "\n",
    "slip = slipConstant(shearMod, np.pi * rCross**2, mO)\n",
    "\n",
    "sort = slip.argsort()\n",
    "print(slip[sort[::-1]])\n",
    "\n",
    "print('are my units correct?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dMW = dnew.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dMW['radius'] = rCross\n",
    "dMW['slip'] = slip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dMW.to_csv('LaqAlldf.final', index = False, sep= '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dReload = pd.read_csv('LaqAlldf.final', delimiter= '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See if things are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'indN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5d9603bc8370>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m mapArrNOe, duplicatedNO, indmissingNO = compInds(\n\u001b[0;32m----> 2\u001b[0;31m     indN, indO, returnExtra = True)\n\u001b[0m\u001b[1;32m      3\u001b[0m mapArrONe, duplicatedON, indmissingON = compInds(\n\u001b[1;32m      4\u001b[0m     indO, indN, returnExtra = True)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'indN' is not defined"
     ]
    }
   ],
   "source": [
    "mapArrNOe, duplicatedNO, indmissingNO = compInds(\n",
    "    indN, indO, returnExtra = True)\n",
    "mapArrONe, duplicatedON, indmissingON = compInds(\n",
    "    indO, indN, returnExtra = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that no HM or JG events are missing\n",
    "gone = np.array([indmissingON])[0]\n",
    "\n",
    "missingBoolON = np.zeros(ftyO.shape, dtype = bool)\n",
    "missingBoolON[gone[:, 0]] = True\n",
    "\n",
    "print(indO[((ftyO == 'HM') * missingBoolON)]) # if empty, nothing is missing\n",
    "print(indO[((ftyO == 'JG') * missingBoolON)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T19:49:17.230903Z",
     "start_time": "2019-03-10T19:49:14.348295Z"
    }
   },
   "outputs": [],
   "source": [
    "mNO = mO[mapArrNOe]\n",
    "mON = mN[mapArrONe]\n",
    "\n",
    "color = np.empty(mO.size, dtype = object)\n",
    "color[ftyO == 'HM'] = 'red'\n",
    "color[ftyO == 'JG'] = 'green'\n",
    "color[ftyO == 'MP'] = 'blue'\n",
    "color[ftyO == '0' ] = 'black'\n",
    "\n",
    "size = 45 * np.ones(mO.size, dtype = float)\n",
    "size[ftyO == '0'] *= 1/15\n",
    "\n",
    "plt.scatter(mO, mON, c = color, s = size )\n",
    "plt.plot([-1, 7],[-1, 7])\n",
    "plt.xlim((-1, 7))\n",
    "plt.ylim((-1, 7))\n",
    "\n",
    "plt.xlabel('m in old file')\n",
    "plt.ylabel('m in new file where indicies matches those in old file')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "color = np.empty(mN.size, dtype = object)\n",
    "color[ftyN == 'HM'] = 'red'\n",
    "color[ftyN == 'JG'] = 'green'\n",
    "color[ftyN == 'MP'] = 'blue'\n",
    "color[ftyN == '0' ] = 'black'\n",
    "\n",
    "size = 45 * np.ones(mN.size, dtype = float)\n",
    "size[ftyN == '0'] *= 1/15\n",
    "\n",
    "plt.scatter(mN, mNO, c = color, s = size)\n",
    "plt.plot([-1, 7],[-1, 7])\n",
    "plt.xlim((-1, 7))\n",
    "plt.ylim((-1, 7))\n",
    "\n",
    "plt.xlabel('m in new file')\n",
    "plt.ylabel('m in old file where indicies matches those in new file')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentNew = radTomO(rCross, 3e6, 0.25)\n",
    "momentMagNew = mOtomW(momentNew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data from online"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of format: csv: ascii complete description of each single solution. Order of fields is: ev_id, date, time_orig (hh:mm:ss), time_orig_decimals (secs/10), latitude, longitude, depth(km), Mb, Ms, region, source_type, bwave_n_stations, bwave_n_inv, bwave_cutoff, mwave_n_stations, mwave_n_inv, mwave_cutoff, swave_n_stations, swave_n_inv, swave_cutoff, dcouple, centroid_time, delta_centroid_time, centroid_lat, delta_centroid_lat, centroid_long, delta_centroid_long, centroid_depth, delta_centroid_depth, prof, half_dur, inv_date_string, exp, mrr, delta_mrr, mss, delta_mss, mee, delta_mee, mrs, delta_mrs, mre, delta_mre, mse, delta_mse, eigen_t, plunge_t, strike_t, eigen_n, plunge_n, strike_n, eigen_p, plunge_p, strike_p, scalar_moment, strike1, dip1, rake1, strike2, dip2, rake2, Mw, status_flag, quality_flag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T18:33:23.864997Z",
     "start_time": "2019-03-10T18:33:23.656859Z"
    }
   },
   "outputs": [],
   "source": [
    "# load pon file\n",
    "\n",
    "# Seismic moment tensors of the April 2009, L'Aquila (Central Italy), earthquake sequence\n",
    "# http://rcmt2.bo.ingv.it/\n",
    "\n",
    "cmtFile = 'Italydataset1976-2015.csv'\n",
    "cmtPd = pd.read_csv(cmtFile)\n",
    "cmtPd.values.T.shape\n",
    "\n",
    "[ev_id,\n",
    "date_orig, \n",
    "time_orig, \n",
    "time_orig_decimals, \n",
    "latitude, \n",
    "longitude, \n",
    "depth, \n",
    "Mb, \n",
    "Ms, \n",
    "region, \n",
    "source_type, \n",
    "bwave_n_stations, \n",
    "bwave_n_inv, \n",
    "bwave_cutoff, \n",
    "mwave_n_stations, \n",
    "mwave_n_inv, \n",
    "mwave_cutoff, \n",
    "swave_n_stations, \n",
    "swave_n_inv, \n",
    "swave_cutoff, \n",
    "dcouple, \n",
    "centroid_time, \n",
    "delta_centroid_time, \n",
    "centroid_lat, \n",
    "delta_centroid_lat, \n",
    "centroid_long, \n",
    "delta_centroid_long, \n",
    "centroid_depth, \n",
    "delta_centroid_depth, \n",
    "prof, \n",
    "half_dur, \n",
    "inv_date_string, \n",
    "exp, \n",
    "mrr, \n",
    "delta_mrr,\n",
    "mss,\n",
    "delta_mss,\n",
    "mee,\n",
    "delta_mee,\n",
    "mrs,\n",
    "delta_mrs,\n",
    "mre,\n",
    "delta_mre,\n",
    "mse,\n",
    "delta_mse,\n",
    "eigen_t,\n",
    "plunge_t,\n",
    "strike_t,\n",
    "eigen_n,\n",
    "plunge_n,\n",
    "strike_n,\n",
    "eigen_p,\n",
    "plunge_p,\n",
    "strike_p,\n",
    "scalar_moment, \n",
    "strike1,\n",
    "dip1,\n",
    "rake1,\n",
    "strike2,\n",
    "dip2,\n",
    "rake2,\n",
    "Mw,\n",
    "status_flag,\n",
    "quality_flag] = cmtPd.values.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T18:33:23.933581Z",
     "start_time": "2019-03-10T18:33:23.875199Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter irrelevant events from the pon file\n",
    "\n",
    "timepon = (date_orig+'T'+time_orig).astype('datetime64[ms]')\n",
    "tkeep = ( (timepon>to.min()) * (timepon<to.max()) * \n",
    "(latitude<lato.max()) * (latitude>lato.min()) *\n",
    " (longitude<lono.max()) * (longitude>lono.min()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T18:33:24.028712Z",
     "start_time": "2019-03-10T18:33:23.945294Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build function to determin similarity of events.\n",
    "\n",
    "def normSimilarities(a, b):\n",
    "    \"\"\"Finds difference between events as norm of each input quantity.\"\"\"\n",
    "    normArr = np.zeros((a.shape[0], b.shape[0]) )\n",
    "    for i in np.arange(normArr.shape[0]):\n",
    "        thingsSquared = np.zeros(b.shape[0])\n",
    "        for j in np.arange(a.shape[1]):\n",
    "            thingsSquared += (a[i,j]-b[:,j])**2\n",
    "        normArr[i] = np.sqrt(thingsSquared)\n",
    "    return normArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T18:33:24.303991Z",
     "start_time": "2019-03-10T18:33:24.036757Z"
    }
   },
   "outputs": [],
   "source": [
    "# making variables to represent events. \n",
    "\n",
    "\n",
    "# Get linear spatal coordinate system\n",
    "latc, lonc = 42, 13\n",
    "ypon, xpon = ChangeAxis(latc, lonc, latitude, longitude)\n",
    "dpon = depth * 1000\n",
    "# ypon = ypon[tkeep]\n",
    "xpon = xpon[tkeep]\n",
    "dpon = dpon[tkeep]\n",
    "yold, xold = ChangeAxis(latc, lonc, lato, lono)\n",
    "dold = do\n",
    "ynew, xnew = ChangeAxis(latc, lonc, latN, lonN)\n",
    "dnew = depthN * 1000\n",
    "\n",
    "\n",
    "# Magnitude of time of events\n",
    "mpon = Mw[tkeep].copy()\n",
    "tpon = timepon[tkeep].astype('datetime64').astype('float64').copy()\n",
    "\n",
    "mnew = mN.copy() \n",
    "tnew = timeN.astype('datetime64').astype('float64').copy()\n",
    "\n",
    "# Filter events from INGV file which are too small for me to care about\n",
    "\n",
    "keepINGVNew = mnew>2\n",
    "xnew = xnew[keepINGVNew]\n",
    "ynew = ynew[keepINGVNew]\n",
    "dnew = dnew[keepINGVNew] \n",
    "mnew = mnew[keepINGVNew]\n",
    "tnew = tnew[keepINGVNew]\n",
    "\n",
    "\n",
    "# scale values to avoid any quantity having to much or little weight\n",
    "\n",
    "mnew = mnew + 1\n",
    "print('adding to mnew')\n",
    "mpon = mpon\n",
    "mnew *= 1\n",
    "mpon *= 1\n",
    "\n",
    "msubtract = mpon.min()\n",
    "tsubtract = tpon.min()\n",
    "\n",
    "mpon = mpon - msubtract\n",
    "mnew = mnew - msubtract\n",
    "tpon = tpon - tsubtract\n",
    "tnew = tnew - tsubtract\n",
    "\n",
    "rangeFactor = xpon.max() - xpon.min()\n",
    "tFactor = tnew.max() - tnew.min()\n",
    "mFactor = mnew.max() - mnew.min()\n",
    "\n",
    "# tpon = tpon / tFactor * rangeFactor\n",
    "# tnew = tnew / tFactor * rangeFactor\n",
    "tpon *= 1/1000\n",
    "tnew *= 1/1000\n",
    "print('using time as seconds')\n",
    "\n",
    "mpon = mpon / mFactor * rangeFactor\n",
    "mnew = mnew / mFactor * rangeFactor\n",
    "\n",
    "ppon = np.array([xpon, ypon, dpon, tpon, mpon]).T\n",
    "pnew = np.array([xnew, ynew, dnew, tnew, mnew]).T\n",
    "\n",
    "ppon = np.array([tpon]).T\n",
    "pnew = np.array([tnew]).T\n",
    "print('trying just time')\n",
    "        \n",
    "sims = normSimilarities(ppon, pnew)\n",
    "sims.shape\n",
    "\n",
    "scaleTime = 1\n",
    "tpon = tpon * scaleTime\n",
    "tnew = tnew * scaleTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T18:33:24.369043Z",
     "start_time": "2019-03-10T18:33:24.313136Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make sure that there was a good match\n",
    "minsim = sims.min()\n",
    "for i in range(sims.shape[0]):\n",
    "    sortinds = sims[i].argsort()\n",
    "    sortinds0 = sortinds[0]\n",
    "#     print(sortinds[:20]) # which indecies were closest. This should almost look random\n",
    "    print(sims[i][sortinds][0:5]) # how distinct are the most similar events?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T18:33:26.939721Z",
     "start_time": "2019-03-10T18:33:24.375685Z"
    }
   },
   "outputs": [],
   "source": [
    "# verify that filtering of pon file seems ok\n",
    "\n",
    "plt.scatter(xold, yold, c = 'red')\n",
    "plt.scatter(xpon, ypon,  s = Mw[tkeep].astype('float')**10/100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
